from transformers import pipeline
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import random

# ğŸ”¹ Carregar modelo DistilBERT para Perguntas e Respostas
qa_pipeline = pipeline("question-answering", model="distilbert-base-uncased-distilled-squad")

# ğŸ”¹ Carregar modelo para Embeddings (Sentence-BERT)
embedding_model = SentenceTransformer('paraphrase-MiniLM-L12-v2')

# ğŸ”¹ Banco de Perguntas e Respostas (Definido diretamente no cÃ³digo)
perguntas_respostas = {
    "Qual Ã© o seu nome?": "Meu nome Ã© Eduardo Rodrigues Sparremberger.",
    "Quantos anos vocÃª tem?": "Eu tenho 22 anos.",
    "Onde vocÃª mora?": "Eu moro em Itati.",
    "Qual Ã© a sua formaÃ§Ã£o acadÃªmica?": "Eu sou estudante de AnÃ¡lise e Desenvolvimento de Sistemas e estudo sobre JavaScript.",
    "Onde vocÃª estuda?": "Eu estudo na Universidade FASUL, no curso de AnÃ¡lise e Desenvolvimento de Sistemas.",
    "VocÃª tem irmÃ£os?": "Sim, eu tenho um irmÃ£o mais velho chamado Daniel.",
    "VocÃª tem filhos? Ou esposa?": "Eu estou esperando uma filha chamada Mavie. Sim, tenho esposa chamada Eziane da Silva Eberhardt!",
    "Quais sÃ£o seus objetivos de vida?": "Meu objetivo Ã© me formar em tecnologia, trabalhar com IA e viajar pelo mundo.",
    "VocÃª tem algum sonho que quer realizar?": "Sim, quero aprender a programar em vÃ¡rias linguagens e criar meu prÃ³prio negÃ³cio.",
    "Me fale sobre Eziane?": "Eziane da Silva Eberhardt Ã© minha esposa e mÃ£e da minha filha Mavie.",
    "Mavie?": "Mavie Ã© filha de Eduardo Rodrigues Sparremberger e Eziane da Silva Eberhardt.",
    "Alan?": "Alan Ã© filho de Eziane da Silva Eberhardt.",
    "Quantos filhos?": "Uma filha chamada Mavie.",
    "De quem Ã© a Mavie?": "Mavie Ã© filha de Eduardo Rodrigues Sparremberger e Eziane da Silva Eberhardt.",
    "Onde eu moro?": "Eu moro em Itati, Rio Grande do Sul.",
    "Quem vai ganhar o GauchÃ£o?": "Claro que o GrÃªmio, Sr. Eduardo!!!"
}

# ğŸ”¹ FunÃ§Ã£o para gerar embeddings das perguntas
def gerar_embeddings(perguntas):
    return np.array(embedding_model.encode(perguntas, normalize_embeddings=True))  # NormalizaÃ§Ã£o melhora precisÃ£o

# ğŸ”¹ FunÃ§Ã£o para encontrar a melhor resposta
def encontrar_resposta(pergunta_usuario):
    # Criar lista de perguntas armazenadas
    perguntas = list(perguntas_respostas.keys())
    respostas = list(perguntas_respostas.values())

    # Gerar embeddings das perguntas
    perguntas_embeddings = gerar_embeddings(perguntas)
    
    # Gerar embedding da pergunta do usuÃ¡rio
    embedding_pergunta_usuario = embedding_model.encode([pergunta_usuario], normalize_embeddings=True)

    # Calcular a similaridade entre a pergunta do usuÃ¡rio e as perguntas armazenadas
    similaridades = cosine_similarity(embedding_pergunta_usuario, perguntas_embeddings)[0]
    
    # Encontrar a pergunta mais similar
    indice_mais_similar = np.argmax(similaridades)
    maior_similaridade = similaridades[indice_mais_similar]

    # Se a similaridade for alta o suficiente, retornar a resposta armazenada
    if maior_similaridade > 0.6:  # Limite de similaridade
        return respostas[indice_mais_similar]
    
    # Caso contrÃ¡rio, usar DistilBERT para responder
    context = " ".join(respostas)
    result = qa_pipeline(question=pergunta_usuario, context=context)
    
    return result['answer'] if result['score'] > 0.5 else "Desculpe, nÃ£o consegui encontrar uma resposta precisa para a sua pergunta."

# ğŸ”¹ FunÃ§Ã£o principal para interagir com a IA
def interagir_com_ia():
    print("ğŸ¤– IA: OlÃ¡! Como posso ajudÃ¡-lo?")
    
    while True:
        pergunta_usuario = input("\nVocÃª: ")
        
        if pergunta_usuario.lower() in ['sair', 'exit', 'quit']:
            print("ğŸ¤– IA: AtÃ© logo!")
            break
        
        resposta = encontrar_resposta(pergunta_usuario)
        print(f"ğŸ¤– IA: {resposta}")

# ğŸ”¹ Executando a interaÃ§Ã£o com a IA
if __name__ == "__main__":
    interagir_com_ia()
